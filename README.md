
Incremental Processing Pipeline to power Aurora Postgres SQL from Hudi Transcational Datalake 

![sa drawio (2)](https://user-images.githubusercontent.com/39345855/222936650-d637dad4-b0d8-464b-a587-9cc205749769.png)

### Watch the Video for hands on Lab
#### Link <Uploaded Soon>


* Let's explore how to create an incremental processing pipeline that powers downstream applications and systems from a transactional data lake. This will demonstrate how to use incremental batch processing to feed an Aurora Posgres SQL database from Hudi. With the help of incremental batch processing, we will load the CDC events into Aurora landing from  transactional datalake. From there, we'll DEDUP the data, clean it up, and enter the staging area.

* Let's explore how to create an incremental processing pipeline that powers downstream applications and systems from a transactional data lake. This will demonstrate how to use incremental batch processing to feed an Aurora Posgres SQL database from Hudi. With the help of incremental batch processing, we will load the CDC events into Aurora landing from  transactional datalake. From there, we'll DEDUP the data, clean it up, and enter the staging area.

1.	Faster query processing: Incremental processing can speed up query processing by reducing the amount of data that needs to be processed. This can result in faster query response times and improved performance.


2.	Reduced processing costs: By processing only the new or modified data, incremental processing can reduce the amount of processing resources needed, such as compute and storage, resulting in lower processing costs.


3.	Improved data freshness: Because incremental processing focuses only on the new or modified data, it enables near real-time processing of data. This means that data is more up-to-date and reflects the most recent changes.


4.	Improved data accuracy: Incremental processing can improve data accuracy by processing only the data that has changed since the last query or computation. This means that there is less risk of errors or discrepancies in the data.


5.	Simplified data processing: Incremental processing can simplify the data processing workflow by reducing the amount of data that needs to be managed and processed. This can make it easier to manage and process large volumes of data.
